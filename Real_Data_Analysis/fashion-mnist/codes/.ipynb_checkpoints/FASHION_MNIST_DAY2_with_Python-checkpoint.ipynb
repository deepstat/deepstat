{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASHION MNIST with Python (DAY 2)\n",
    "\n",
    "DATA SOURCE : https://www.kaggle.com/zalando-research/fashionmnist (Kaggle, Fashion MNIST)\n",
    "\n",
    "FASHION MNIST with Python (DAY 1) : http://deepstat.tistory.com/35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing numpy, pandas, pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"..\\\\datasets\\\\fashion-mnist_train.csv\")\n",
    "data_test = pd.read_csv(\"..\\\\datasets\\\\fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train_y = data_train.label\n",
    "y_test = data_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = data_train.drop(\"label\",axis=1)/256\n",
    "x_test = data_test.drop(\"label\",axis=1)/256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting valid and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "valid2_idx = np.random.choice(60000,10000,replace = False)\n",
    "valid1_idx = np.random.choice(list(set(range(60000)) - set(valid2_idx)),10000,replace=False)\n",
    "train_idx = list(set(range(60000))-set(valid1_idx)-set(valid2_idx))\n",
    "\n",
    "x_train = data_train_x.iloc[train_idx,:]\n",
    "y_train = data_train_y.iloc[train_idx]\n",
    "\n",
    "x_valid1 = data_train_x.iloc[valid1_idx,:]\n",
    "y_valid1 = data_train_y.iloc[valid1_idx]\n",
    "\n",
    "x_valid2 = data_train_x.iloc[valid2_idx,:]\n",
    "y_valid2 = data_train_y.iloc[valid2_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\stat413server1\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_model = BaggingClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3974,    0,    0,    4,    1,    0,   50,    0,    0,    0],\n",
       "       [   0, 3988,    0,    3,    1,    0,    0,    0,    0,    0],\n",
       "       [   2,    0, 4046,    1,   15,    0,   33,    0,    1,    0],\n",
       "       [   7,    2,    1, 3914,    9,    0,    6,    0,    2,    0],\n",
       "       [   0,    0,    6,    4, 3984,    0,   27,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0, 3930,    0,    7,    0,    4],\n",
       "       [   9,    0,    2,    3,    6,    0, 3886,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    2,    0, 4093,    0,   16],\n",
       "       [   2,    0,    1,    0,    0,    0,    3,    0, 3942,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    3,    0, 4009]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(BG_model.predict(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY = 0.99415\n"
     ]
    }
   ],
   "source": [
    "BG_model_train_acc = (BG_model.predict(x_train) == y_train).mean()\n",
    "print(\"TRAINING ACCURACY =\",BG_model_train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 852,    7,   13,   38,    5,    0,  182,    0,    7,    0],\n",
       "       [   5,  985,    1,   13,    2,    0,    2,    0,    1,    0],\n",
       "       [  10,    6,  761,    9,  113,    0,  127,    0,    4,    0],\n",
       "       [  40,   22,   10,  911,   50,    1,   24,    0,    3,    0],\n",
       "       [   4,    1,   99,   24,  771,    0,  105,    0,    9,    0],\n",
       "       [   1,    0,    0,    0,    0, 1004,    1,   31,    5,   20],\n",
       "       [  97,    5,   54,   16,   49,    0,  533,    0,   12,    0],\n",
       "       [   0,    0,    0,    0,    0,   34,    0,  879,    3,   48],\n",
       "       [   6,    0,    7,    1,    5,    3,   13,    3,  990,    3],\n",
       "       [   0,    0,    0,    0,    0,   18,    0,   35,    0,  907]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(BG_model.predict(x_valid1),y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY = 0.8593\n"
     ]
    }
   ],
   "source": [
    "BG_model_valid1_acc = (BG_model.predict(x_valid1) == y_valid1).mean()\n",
    "print(\"VALIDATION ACCURACY =\",BG_model_valid1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN_ACC': 0.99415, 'VALID_ACC': 0.8593}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"TRAIN_ACC\" : BG_model_train_acc , \"VALID_ACC\" : BG_model_valid1_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3985,    1,    2,    0,    4,    0,   45,    0,    1,    0],\n",
       "       [   0, 3983,    0,    1,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 4037,    2,   20,    0,   25,    0,    1,    0],\n",
       "       [   3,    6,    3, 3921,    8,    0,   10,    0,    0,    0],\n",
       "       [   0,    0,   11,    3, 3980,    0,   24,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0, 3929,    0,   10,    0,    2],\n",
       "       [   4,    0,    3,    2,    3,    0, 3900,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    3,    0, 4088,    0,   11],\n",
       "       [   2,    0,    0,    0,    1,    0,    1,    0, 3942,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    5,    0, 4016]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(RF_model.predict(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY = 0.994525\n"
     ]
    }
   ],
   "source": [
    "RF_model_train_acc = (RF_model.predict(x_train) == y_train).mean()\n",
    "print(\"TRAINING ACCURACY =\",RF_model_train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 856,    8,   15,   31,   10,    0,  182,    0,    6,    0],\n",
       "       [   1,  988,    3,    7,    3,    0,    1,    0,    1,    0],\n",
       "       [  14,    5,  747,    6,  133,    0,  160,    0,    9,    0],\n",
       "       [  40,   18,   11,  912,   58,    0,   28,    0,    6,    0],\n",
       "       [   6,    1,  109,   31,  739,    0,   95,    0,    2,    0],\n",
       "       [   0,    0,    0,    0,    0, 1002,    0,   31,    7,   23],\n",
       "       [  93,    6,   54,   24,   46,    0,  502,    0,   14,    0],\n",
       "       [   0,    0,    0,    0,    0,   35,    0,  874,    1,   49],\n",
       "       [   5,    0,    6,    0,    6,    3,   19,    2,  988,    3],\n",
       "       [   0,    0,    0,    1,    0,   20,    0,   41,    0,  903]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(RF_model.predict(x_valid1),y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY = 0.8511\n"
     ]
    }
   ],
   "source": [
    "RF_model_valid1_acc = (RF_model.predict(x_valid1) == y_valid1).mean()\n",
    "print(\"VALIDATION ACCURACY =\",RF_model_valid1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN_ACC': 0.994525, 'VALID_ACC': 0.8511}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"TRAIN_ACC\" : RF_model_train_acc , \"VALID_ACC\" : RF_model_valid1_acc}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
