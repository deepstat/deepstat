{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "http://jorditorres.org/first-contact-with-tnesorflow/#cap5 (First Contact with tensorflow)\n",
    "\n",
    "https://deepstat.tistory.com/11 (Convolutional Neural Network (ver. Python)\n",
    "\n",
    "https://deepstat.tistory.com/12 (Convolutional Neural Network (ver. R)\n",
    "\n",
    "http://fluxml.ai/ (flux: The Elegant Machine Learning Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Convolutional Neural Network (ver. Flux in Julia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport tensorflow.keras.datasets.mnist as MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple{Array{UInt8,3},Array{UInt8,1}}\n",
      "Tuple{Array{UInt8,3},Array{UInt8,1}}\n"
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = MNIST.load_data()\n",
    "println(typeof(mnist_train))\n",
    "println(typeof(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `next_batch`라는 함수 만들기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct My_data\n",
    "    data::Tuple\n",
    "    start_n::Int\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function next_batch(data::My_data, n::Int)\n",
    "    start_n = data.start_n\n",
    "    end_n = data.start_n + n - 1\n",
    "    batch_X = float(data.data[1][start_n:end_n,:,:])\n",
    "    reshape_batch_X = reshape(batch_X, (:,28,28,1))\n",
    "    batch_Y = data.data[2][start_n:end_n]\n",
    "    data.start_n = (end_n+1) % (size(data.data[1])[1])\n",
    "    return (permutedims(reshape_batch_X, (2,3,4,1)), Flux.onehotbatch(batch_Y, 0:9))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = My_data(mnist_train,1)\n",
    "test_dat = My_data(mnist_test,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모형 설정\n",
    "\n",
    "input -> conv1 -> pool1 -> conv2 -> pool2 -> [inner product -> relu] -> dropout -> [inner product -> softmax] -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "    Conv((5,5), 1=>32, relu, pad = 2),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "    Conv((5,5), 32=>64, relu, pad = 2),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(7*7*64,1024),Dropout(0.5),\n",
    "    Dense(1024,10),softmax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function : cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.crossentropy(m(x),y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy(x, y) = mean(Flux.onecold(m(x)) .== Flux.onecold(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer : ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_opt (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARS = params(m)\n",
    "\n",
    "function my_opt(n, lr)\n",
    "    for i = 0:n\n",
    "        train_loss_vec = zeros(30)\n",
    "        test_acc = zeros(2)\n",
    "        for j in 1:30\n",
    "            train_X, train_Y = next_batch(train_dat,2000)\n",
    "            Flux.train!(loss, [(train_X, train_Y)], ADAM(PARS, lr))\n",
    "            train_loss_vec[j] = loss(train_X,train_Y).data\n",
    "        end\n",
    "    \n",
    "        if i % 1 == 0\n",
    "            Flux.testmode!(m)\n",
    "            for k in 1:2\n",
    "                test_X, test_Y = next_batch(test_dat,5000)\n",
    "                test_acc[k] = Accuracy(test_X, test_Y)\n",
    "            end\n",
    "            Flux.testmode!(m,false)\n",
    "        \n",
    "            println(\"step:\",i,\"  train_loss:\" ,mean(train_loss_vec),\"  test_acc:\" ,mean(test_acc))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0  train_loss:1.3885555539232082  test_acc:0.9097\n"
     ]
    }
   ],
   "source": [
    "my_opt(0,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0  train_loss:0.0982832379538861  test_acc:0.9778\n",
      "step:1  train_loss:0.058798922099351454  test_acc:0.9823\n",
      "step:2  train_loss:0.04470948472953977  test_acc:0.9859\n",
      "step:3  train_loss:0.03683575338240497  test_acc:0.9871000000000001\n",
      "step:4  train_loss:0.030979322538068232  test_acc:0.9881\n",
      "step:5  train_loss:0.026548839185737916  test_acc:0.9887\n",
      "step:6  train_loss:0.023549122782400043  test_acc:0.9896\n",
      "step:7  train_loss:0.021146819852282873  test_acc:0.9904\n",
      "step:8  train_loss:0.01909730216469945  test_acc:0.9904999999999999\n",
      "step:9  train_loss:0.016190657155984105  test_acc:0.9912000000000001\n",
      "step:10  train_loss:0.015597942537344192  test_acc:0.9912\n"
     ]
    }
   ],
   "source": [
    "my_opt(10, 0.0001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
