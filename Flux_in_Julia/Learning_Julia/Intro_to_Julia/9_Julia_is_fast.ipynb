{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "## Reference\n",
    "\n",
    "https://github.com/JuliaComputing/JuliaBoxTutorials/tree/master/introductory-tutorials/intro-to-julia (github : JuliaComputing/JuliaBoxTutorials/introductory-tutorials/intro-to-julia/)\n",
    "\n",
    "Topics:\n",
    "\n",
    "1. [Define the sum function](#1)\n",
    "2. [Implementations & benchmarking of sum in...](#2)\n",
    "    1. [C (hand-written)](#2.A)\n",
    "    2. [C (hand-written with -ffast-math)](#2.B)\n",
    "    3. [python (built-in)](#2.C)\n",
    "    4. [python (numpy)](#2.D)\n",
    "    5. [python (hand-written)](#2.E)\n",
    "    6. [Julia (built-in)](#2.F)\n",
    "    7. [Julia (hand-written)](#2.G)\n",
    "    8. [Julia (hand-written with SIMD)](#2.H)\n",
    "3. [Summary of benchmarks](#3)\n",
    "\n",
    "### Series\n",
    "\n",
    "- http://deepstat.tistory.com/45 (01. Getting started)(in English)\n",
    "- http://deepstat.tistory.com/46 (01. Getting started(한글))\n",
    "- http://deepstat.tistory.com/47 (02. Strings)(in English)\n",
    "- http://deepstat.tistory.com/48 (02. Strings(한글))\n",
    "- http://deepstat.tistory.com/49 (03. Data structures)(in English)\n",
    "- http://deepstat.tistory.com/50 (03. Data structures(한글))\n",
    "- http://deepstat.tistory.com/51 (04. Loops)(in English)\n",
    "- http://deepstat.tistory.com/52 (04. Loops(한글))\n",
    "- http://deepstat.tistory.com/53 (05. Conditionals)(in English)\n",
    "- http://deepstat.tistory.com/54 (05. Conditionals(한글))\n",
    "- http://deepstat.tistory.com/55 (06. Functions)(in English)\n",
    "- http://deepstat.tistory.com/56 (06. Functions(한글))\n",
    "- http://deepstat.tistory.com/57 (07. Packages)(in English)\n",
    "- http://deepstat.tistory.com/58 (07. Packages(한글))\n",
    "- http://deepstat.tistory.com/59 (08. Plotting)(in English)\n",
    "- http://deepstat.tistory.com/60 (08. Plotting(한글))\n",
    "- http://deepstat.tistory.com/62 (09. Julia is fast(한글))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, benchmarks are used to compare languages. These benchmarks can lead to long discussions, first as to exactly what is being benchmarked and secondly what explains the differences. These simple questions can sometimes get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT: https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the sum function <a id=1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the sum function sum(a), which computes $$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$ where $n$ is the length of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Float64,1}:\n",
       " 0.5269491225334235  \n",
       " 0.19706199325984275 \n",
       " 0.23592456884028135 \n",
       " 0.027500385222536616\n",
       " 0.41237634926292355 \n",
       " 0.49877120777765604 \n",
       " 0.19438800783198507 \n",
       " 0.32757751795945067 \n",
       " 0.5192727133968746  \n",
       " 0.4315287732872737  \n",
       " 0.8990672827433108  \n",
       " 0.4407671101300359  \n",
       " 0.9814272231753296  \n",
       " ⋮                   \n",
       " 0.6125295441451339  \n",
       " 0.041324486675398786\n",
       " 0.6543162400651628  \n",
       " 0.15135956476295687 \n",
       " 0.3108763380233237  \n",
       " 0.6905120191561878  \n",
       " 0.5642808289984709  \n",
       " 0.1535877856700727  \n",
       " 0.8338274357103401  \n",
       " 0.19755217821574522 \n",
       " 0.4735443129236854  \n",
       " 0.9515910556915412  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rand(10^7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9996703916066885e6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is 0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations & benchmarking of sum in... <a id=2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.007909 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.9996703916066885e6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.011878 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.9996703916066885e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.010598 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.9996703916066885e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The @time macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a BenchmarkTools.jl package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A C (hand-written) <a id=2.A></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the \"\"\" wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.99967039160726e6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.718320608139038e-7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sum(a) - sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isapprox (generic function with 8 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "≈  # alias for the `isapprox` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mx\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "isapprox(x, y; rtol::Real=atol>0 ? 0 : √eps, atol::Real=0, nans::Bool=false, norm::Function)\n",
       "```\n",
       "\n",
       "Inexact equality comparison: `true` if `norm(x-y) <= max(atol, rtol*max(norm(x), norm(y)))`. The default `atol` is zero and the default `rtol` depends on the types of `x` and `y`. The keyword argument `nans` determines whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "For real or complex floating-point values, if an `atol > 0` is not specified, `rtol` defaults to the square root of [`eps`](@ref) of the type of `x` or `y`, whichever is bigger (least precise). This corresponds to requiring equality of about half of the significand digits. Otherwise, e.g. for integer arguments or if an `atol > 0` is supplied, `rtol` defaults to zero.\n",
       "\n",
       "`x` and `y` may also be arrays of numbers, in which case `norm` defaults to `vecnorm` but may be changed by passing a `norm::Function` keyword argument. (For numbers, `norm` is the same thing as `abs`.) When `x` and `y` are arrays, if `norm(x-y)` is not finite (i.e. `±Inf` or `NaN`), the comparison falls back to checking whether all elements of `x` and `y` are approximately equal component-wise.\n",
       "\n",
       "The binary operator `≈` is equivalent to `isapprox` with the default arguments, and `x ≉ y` is equivalent to `!isapprox(x,y)`.\n",
       "\n",
       "Note that `x ≈ 0` (i.e., comparing to zero with the default tolerances) is equivalent to `x == 0` since the default `atol` is `0`.  In such cases, you should either supply an appropriate `atol` (or use `norm(x) ≤ atol`) or rearrange your code (e.g. use `x ≈ y` rather than `x - y ≈ 0`).   It is not possible to pick a nonzero `atol` automatically because it depends on the overall scaling (the \"units\") of your problem: for example, in `x - y ≈ 0`, `atol=1e-9` is an absurdly small tolerance if `x` is the [radius of the Earth](https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly large tolerance if `x` is the [radius of a Hydrogen atom](https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> 0.1 ≈ (0.1 - 1e-10)\n",
       "true\n",
       "\n",
       "julia> isapprox(10, 11; atol = 2)\n",
       "true\n",
       "\n",
       "julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\n",
       "true\n",
       "\n",
       "julia> 1e-10 ≈ 0\n",
       "false\n",
       "\n",
       "julia> isapprox(1e-10, 0, atol=1e-8)\n",
       "true\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  isapprox(x, y; rtol::Real=atol>0 ? 0 : √eps, atol::Real=0, nans::Bool=false, norm::Function)\u001b[39m\n",
       "\n",
       "  Inexact equality comparison: \u001b[36mtrue\u001b[39m if \u001b[36mnorm(x-y) <= max(atol,\n",
       "  rtol*max(norm(x), norm(y)))\u001b[39m. The default \u001b[36matol\u001b[39m is zero and the default \u001b[36mrtol\u001b[39m\n",
       "  depends on the types of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m. The keyword argument \u001b[36mnans\u001b[39m determines\n",
       "  whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "  For real or complex floating-point values, if an \u001b[36matol > 0\u001b[39m is not specified,\n",
       "  \u001b[36mrtol\u001b[39m defaults to the square root of \u001b[36meps\u001b[39m of the type of \u001b[36mx\u001b[39m or \u001b[36my\u001b[39m, whichever is\n",
       "  bigger (least precise). This corresponds to requiring equality of about half\n",
       "  of the significand digits. Otherwise, e.g. for integer arguments or if an\n",
       "  \u001b[36matol > 0\u001b[39m is supplied, \u001b[36mrtol\u001b[39m defaults to zero.\n",
       "\n",
       "  \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m may also be arrays of numbers, in which case \u001b[36mnorm\u001b[39m defaults to\n",
       "  \u001b[36mvecnorm\u001b[39m but may be changed by passing a \u001b[36mnorm::Function\u001b[39m keyword argument.\n",
       "  (For numbers, \u001b[36mnorm\u001b[39m is the same thing as \u001b[36mabs\u001b[39m.) When \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m are arrays, if\n",
       "  \u001b[36mnorm(x-y)\u001b[39m is not finite (i.e. \u001b[36m±Inf\u001b[39m or \u001b[36mNaN\u001b[39m), the comparison falls back to\n",
       "  checking whether all elements of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m are approximately equal\n",
       "  component-wise.\n",
       "\n",
       "  The binary operator \u001b[36m≈\u001b[39m is equivalent to \u001b[36misapprox\u001b[39m with the default arguments,\n",
       "  and \u001b[36mx ≉ y\u001b[39m is equivalent to \u001b[36m!isapprox(x,y)\u001b[39m.\n",
       "\n",
       "  Note that \u001b[36mx ≈ 0\u001b[39m (i.e., comparing to zero with the default tolerances) is\n",
       "  equivalent to \u001b[36mx == 0\u001b[39m since the default \u001b[36matol\u001b[39m is \u001b[36m0\u001b[39m. In such cases, you should\n",
       "  either supply an appropriate \u001b[36matol\u001b[39m (or use \u001b[36mnorm(x) ≤ atol\u001b[39m) or rearrange your\n",
       "  code (e.g. use \u001b[36mx ≈ y\u001b[39m rather than \u001b[36mx - y ≈ 0\u001b[39m). It is not possible to pick a\n",
       "  nonzero \u001b[36matol\u001b[39m automatically because it depends on the overall scaling (the\n",
       "  \"units\") of your problem: for example, in \u001b[36mx - y ≈ 0\u001b[39m, \u001b[36matol=1e-9\u001b[39m is an\n",
       "  absurdly small tolerance if \u001b[36mx\u001b[39m is the radius of the Earth\n",
       "  (https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly\n",
       "  large tolerance if \u001b[36mx\u001b[39m is the radius of a Hydrogen atom\n",
       "  (https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> 0.1 ≈ (0.1 - 1e-10)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(10, 11; atol = 2)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> 1e-10 ≈ 0\u001b[39m\n",
       "\u001b[36m  false\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(1e-10, 0, atol=1e-8)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?isapprox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     8.910 ms (0.00% GC)\n",
       "  median time:      9.422 ms (0.00% GC)\n",
       "  mean time:        9.744 ms (0.00% GC)\n",
       "  maximum time:     23.826 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          513\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Fastest time was 8.909969 msec\n"
     ]
    }
   ],
   "source": [
    "println(\"C: Fastest time was $(minimum(c_bench.times) / 1e6) msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 1 entry:\n",
       "  \"C\" => 8.90997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dict()  # a \"dictionary\", i.e. an associative array\n",
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B C (hand-written with -ffast-math) <a id=2.B></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we allow C to re-arrange the floating point operations, then it'll vectorize with SIMD (single instruction, multiple data) instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum_fastmath (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const Clib_fastmath = tempname()   # make a temporary file\n",
    "\n",
    "# The same as above but with a -ffast-math flag added\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -ffast-math -o $(Clib_fastmath * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum_fastmath(X::Array{Float64}) = ccall((\"c_sum\", Clib_fastmath), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.678 ms (0.00% GC)\n",
       "  median time:      6.029 ms (0.00% GC)\n",
       "  mean time:        7.398 ms (0.00% GC)\n",
       "  maximum time:     18.739 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          675\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_fastmath_bench = @benchmark $c_sum_fastmath($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.678042"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"C -ffast-math\"] = minimum(c_fastmath_bench.times) / 1e6  # in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C python (built-in) <a id=2.C></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyCall package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.add(\"PyCall\")\n",
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.99967039160726e6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  368 bytes\n",
       "  allocs estimate:  8\n",
       "  --------------\n",
       "  minimum time:     965.677 ms (0.00% GC)\n",
       "  median time:      968.887 ms (0.00% GC)\n",
       "  mean time:        972.928 ms (0.00% GC)\n",
       "  maximum time:     996.690 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"C\"               => 8.90997\n",
       "  \"Python built-in\" => 965.677\n",
       "  \"C -ffast-math\"   => 5.67804"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D python (numpy) <a id=2.D></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takes advantage of hardware \"SIMD\", but only works when it works.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy is an optimized C library, callable from Python. It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  368 bytes\n",
       "  allocs estimate:  8\n",
       "  --------------\n",
       "  minimum time:     5.367 ms (0.00% GC)\n",
       "  median time:      5.560 ms (0.00% GC)\n",
       "  mean time:        6.557 ms (0.00% GC)\n",
       "  maximum time:     17.046 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          761\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999670391606692e6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 4 entries:\n",
       "  \"C\"               => 8.90997\n",
       "  \"Python numpy\"    => 5.36704\n",
       "  \"Python built-in\" => 965.677\n",
       "  \"C -ffast-math\"   => 5.67804"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.E python (hand-written) <a id=2.E></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function py_sum at 0x7fd7f32f1ea0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  368 bytes\n",
       "  allocs estimate:  8\n",
       "  --------------\n",
       "  minimum time:     1.038 s (0.00% GC)\n",
       "  median time:      1.043 s (0.00% GC)\n",
       "  mean time:        1.049 s (0.00% GC)\n",
       "  maximum time:     1.069 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.99967039160726e6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"C\"                   => 8.90997\n",
       "  \"Python numpy\"        => 5.36704\n",
       "  \"Python hand-written\" => 1038.46\n",
       "  \"Python built-in\"     => 965.677\n",
       "  \"C -ffast-math\"       => 5.67804"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.F Julia (built-in) <a id=2.F></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written directly in Julia, not in C!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/5d4eaca0c9fa3d555c79dbacdccb9169fdf64b65/base/reducedim.jl#L645\" target=\"_blank\">reducedim.jl:645</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray) in Base at reducedim.jl:645"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.384 ms (0.00% GC)\n",
       "  median time:      5.512 ms (0.00% GC)\n",
       "  mean time:        5.988 ms (0.00% GC)\n",
       "  maximum time:     16.048 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          834\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 6 entries:\n",
       "  \"C\"                   => 8.90997\n",
       "  \"Python numpy\"        => 5.36704\n",
       "  \"Python hand-written\" => 1038.46\n",
       "  \"Python built-in\"     => 965.677\n",
       "  \"Julia built-in\"      => 5.3836\n",
       "  \"C -ffast-math\"       => 5.67804"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.G Julia (hand-written) <a id=2.G></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)   \n",
    "    s = 0.0 # s = zero(eltype(a))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     9.578 ms (0.00% GC)\n",
       "  median time:      9.823 ms (0.00% GC)\n",
       "  mean time:        11.032 ms (0.00% GC)\n",
       "  maximum time:     23.422 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          453\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 7 entries:\n",
       "  \"C\"                   => 8.90997\n",
       "  \"Python numpy\"        => 5.36704\n",
       "  \"Julia hand-written\"  => 9.57754\n",
       "  \"Python hand-written\" => 1038.46\n",
       "  \"Python built-in\"     => 965.677\n",
       "  \"Julia built-in\"      => 5.3836\n",
       "  \"C -ffast-math\"       => 5.67804"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.H Julia (hand-written with SIMD) <a id=2.H></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_simd (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_simd(A)   \n",
    "    s = 0.0 # s = zero(eltype(A))\n",
    "    @simd for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.325 ms (0.00% GC)\n",
       "  median time:      5.414 ms (0.00% GC)\n",
       "  mean time:        5.824 ms (0.00% GC)\n",
       "  maximum time:     16.182 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          857\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_simd = @benchmark mysum_simd($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999670391606648e6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_simd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 8 entries:\n",
       "  \"Julia hand-written simd\" => 5.32519\n",
       "  \"C\"                       => 8.90997\n",
       "  \"Python numpy\"            => 5.36704\n",
       "  \"Julia hand-written\"      => 9.57754\n",
       "  \"Python hand-written\"     => 1038.46\n",
       "  \"Python built-in\"         => 965.677\n",
       "  \"Julia built-in\"          => 5.3836\n",
       "  \"C -ffast-math\"           => 5.67804"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written simd\"] = minimum(j_bench_hand_simd.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of benchmarks <a id=3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia hand-written simd....5.33\n",
      "Python numpy...............5.37\n",
      "Julia built-in.............5.38\n",
      "C -ffast-math..............5.68\n",
      "C..........................8.91\n",
      "Julia hand-written.........9.58\n",
      "Python built-in..........965.68\n",
      "Python hand-written......1038.46\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=2), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
